{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сессия 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import numpy as np\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле представлены 5 функций: <br>pdf_text()<br>load_model()<br>make_pred()<br>cleaning()<br>usr_val()<br><br>Для вызова документации функции введите `print(function.__doc__)`. Для полной документации воспользуйтесь файлом `Программная документация.docx`\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_text(filename):\n",
    "    \"\"\"\n",
    "    Функция получения текста из pdf файла\n",
    "    \n",
    "    PARAMS:\n",
    "    filename(str) - Имя pdf файла с расширением в той же директории или полный путь до файла(пример resume.pdf)\n",
    "    \n",
    "    RETURN:\n",
    "    words(str)\n",
    "    \"\"\"\n",
    "    pdf = pdfplumber.open(filename)\n",
    "    T = []\n",
    "    for i in range(2):\n",
    "        try:\n",
    "            page = pdf.pages[i]\n",
    "            T.append(page.extract_text())\n",
    "        except Exception:\n",
    "            continue\n",
    "    pdf.close()\n",
    "    return \" \".join(T)\n",
    "    \n",
    "def load_model(filename):\n",
    "    \"\"\"\n",
    "    Функция загрузки скомпилированной модели pkl(import pickle)\n",
    "    \n",
    "    PARAMS:\n",
    "    filename(str) - Имя pkl файла с расширением в той же директории или полный путь до файла(пример model.pkl)\n",
    "    \n",
    "    RETURN:\n",
    "    Loaded model\n",
    "    \"\"\"\n",
    "    print(\">>> Загрузка модели\")\n",
    "    with open(filename, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "    print(\">>> Готово\")\n",
    "    return model\n",
    "    \n",
    "def make_pred(model, words, p_num):\n",
    "    \"\"\"\n",
    "    Функция предсказания\n",
    "    \n",
    "    PARAMS:\n",
    "    model - Загруженная модель, используйте load_model() или свою модель \n",
    "    words(str) - Получает загруженные слова из pdf: pdf_text() или стоку с вашими словами\n",
    "    p_num(int) - Количество предсказываемых экземпляров класса\n",
    "    \n",
    "    RETURN:\n",
    "    list of predictions(str)\n",
    "    \"\"\"\n",
    "    print(\">>> Making prediction\")\n",
    "    if p_num==1:\n",
    "        pred = model.predict([words])\n",
    "        return pred\n",
    "    else:\n",
    "        print()\n",
    "        print(\">>> Внимание, тк вы хотите получить более одного результата, имейте в виду, что результат может не соответствовать вашим ожиданиям.\")\n",
    "        R = []\n",
    "        allpreds = model.decision_function([words]).reshape(-1)\n",
    "        for i in allpreds.argsort()[-2:][::-1]:\n",
    "            R.append(model.classes_[i])\n",
    "        return R\n",
    "        \n",
    "def cleaning(words):\n",
    "    \"\"\"\n",
    "    Функция очистки ваших слов от ненужных, таких как союзы, местоимения, часто встречаемые и тп\n",
    "    \n",
    "    PARAMS:\n",
    "    words(str) - Ваши слова\n",
    "    \n",
    "    RETURN:\n",
    "    words(str)\n",
    "    \"\"\"\n",
    "    print(\">>> Всего слов: \", len(words.split()))\n",
    "    a=len(words.split()) \n",
    "    words = re.sub('[–\\n\\r.\"(\"\")\"©•,«»:;%$!@#0-9$a-z]', '', words).lower()\n",
    "    stopwords = [\"тд\",\"c\",\"а\",\"алло\",\"без\",\"белый\",\"близко\",\"более\",\"больше\",\"большой\",\"будем\",\"будет\",\"будете\",\"будешь\",\"будто\",\"буду\",\"будут\",\"будь\",\"бы\",\"бывает\",\"бывь\",\"был\",\"была\",\"были\",\"было\",\"быть\",\"в\",\"важная\",\"важное\",\"важные\",\"важный\",\"вам\",\"вами\",\"вас\",\"ваш\",\"ваша\",\"ваше\",\"ваши\",\"вверх\",\"вдали\",\"вдруг\",\"ведь\",\"везде\",\"вернуться\",\"весь\",\"вечер\",\"взгляд\",\"взять\",\"вид\",\"видел\",\"видеть\",\"вместе\",\"вне\",\"вниз\",\"внизу\",\"во\",\"вода\",\"война\",\"вокруг\",\"вон\",\"вообще\",\"вопрос\",\"восемнадцатый\",\"восемнадцать\",\"восемь\",\"восьмой\",\"вот\",\"впрочем\",\"времени\",\"время\",\"все\",\"все еще\",\"всегда\",\"всего\",\"всем\",\"всеми\",\"всему\",\"всех\",\"всею\",\"всю\",\"всюду\",\"вся\",\"всё\",\"второй\",\"вы\",\"выйти\",\"г\",\"где\",\"главный\",\"глаз\",\"говорил\",\"говорит\",\"говорить\",\"год\",\"года\",\"году\",\"голова\",\"голос\",\"город\",\"да\",\"давать\",\"давно\",\"даже\",\"далекий\",\"далеко\",\"дальше\",\"даром\",\"дать\",\"два\",\"двадцатый\",\"двадцать\",\"две\",\"двенадцатый\",\"двенадцать\",\"дверь\",\"двух\",\"девятнадцатый\",\"девятнадцать\",\"девятый\",\"девять\",\"действительно\",\"дел\",\"делал\",\"делать\",\"делаю\",\"дело\",\"день\",\"деньги\",\"десятый\",\"десять\",\"для\",\"до\",\"довольно\",\"долго\",\"должен\",\"должно\",\"должный\",\"дом\",\"дорога\",\"друг\",\"другая\",\"другие\",\"других\",\"друго\",\"другое\",\"другой\",\"думать\",\"душа\",\"е\",\"его\",\"ее\",\"ей\",\"ему\",\"если\",\"есть\",\"еще\",\"ещё\",\"ею\",\"её\",\"ж\",\"ждать\",\"же\",\"жена\",\"женщина\",\"жизнь\",\"жить\",\"за\",\"занят\",\"занята\",\"занято\",\"заняты\",\"затем\",\"зато\",\"зачем\",\"здесь\",\"земля\",\"знать\",\"значит\",\"значить\",\"и\",\"иди\",\"идти\",\"из\",\"или\",\"им\",\"имеет\",\"имел\",\"именно\",\"иметь\",\"ими\",\"имя\",\"иногда\",\"их\",\"к\",\"каждая\",\"каждое\",\"каждые\",\"каждый\",\"кажется\",\"казаться\",\"как\",\"какая\",\"какой\",\"кем\",\"книга\",\"когда\",\"кого\",\"ком\",\"комната\",\"кому\",\"конец\",\"конечно\",\"которая\",\"которого\",\"которой\",\"которые\",\"который\",\"которых\",\"кроме\",\"кругом\",\"кто\",\"куда\",\"лежать\",\"лет\",\"ли\",\"лицо\",\"лишь\",\"лучше\",\"любить\",\"люди\",\"м\",\"маленький\",\"мало\",\"мать\",\"машина\",\"между\",\"меля\",\"менее\",\"меньше\",\"меня\",\"место\",\"миллионов\",\"мимо\",\"минута\",\"мир\",\"мира\",\"мне\",\"много\",\"многочисленная\",\"многочисленное\",\"многочисленные\",\"многочисленный\",\"мной\",\"мною\",\"мог\",\"могу\",\"могут\",\"мож\",\"может\",\"может быть\",\"можно\",\"можхо\",\"мои\",\"мой\",\"мор\",\"москва\",\"мочь\",\"моя\",\"моё\",\"мы\",\"на\",\"наверху\",\"над\",\"надо\",\"назад\",\"наиболее\",\"найти\",\"наконец\",\"нам\",\"нами\",\"народ\",\"нас\",\"начала\",\"начать\",\"наш\",\"наша\",\"наше\",\"наши\",\"не\",\"него\",\"недавно\",\"недалеко\",\"нее\",\"ней\",\"некоторый\",\"нельзя\",\"нем\",\"немного\",\"нему\",\"непрерывно\",\"нередко\",\"несколько\",\"нет\",\"нею\",\"неё\",\"ни\",\"нибудь\",\"ниже\",\"низко\",\"никакой\",\"никогда\",\"никто\",\"никуда\",\"ним\",\"ними\",\"них\",\"ничего\",\"ничто\",\"но\",\"новый\",\"нога\",\"ночь\",\"ну\",\"нужно\",\"нужный\",\"нх\",\"о\",\"об\",\"оба\",\"обычно\",\"один\",\"одиннадцатый\",\"одиннадцать\",\"однажды\",\"однако\",\"одного\",\"одной\",\"оказаться\",\"окно\",\"около\",\"он\",\"она\",\"они\",\"оно\",\"опять\",\"особенно\",\"остаться\",\"от\",\"ответить\",\"отец\",\"откуда\",\"отовсюду\",\"отсюда\",\"очень\",\"первый\",\"перед\",\"писать\",\"плечо\",\"по\",\"под\",\"подойди\",\"подумать\",\"пожалуйста\",\"позже\",\"пойти\",\"пока\",\"пол\",\"получить\",\"помнить\",\"понимать\",\"понять\",\"пор\",\"пора\",\"после\",\"последний\",\"посмотреть\",\"посреди\",\"потом\",\"потому\",\"почему\",\"почти\",\"правда\",\"прекрасно\",\"при\",\"про\",\"просто\",\"против\",\"процентов\",\"путь\",\"пятнадцатый\",\"пятнадцать\",\"пятый\",\"пять\",\"работа\",\"работать\",\"раз\",\"разве\",\"рано\",\"раньше\",\"ребенок\",\"решить\",\"россия\",\"рука\",\"русский\",\"ряд\",\"рядом\",\"с\",\"с кем\",\"сам\",\"сама\",\"сами\",\"самим\",\"самими\",\"самих\",\"само\",\"самого\",\"самой\",\"самом\",\"самому\",\"саму\",\"самый\",\"свет\",\"свое\",\"своего\",\"своей\",\"свои\",\"своих\",\"свой\",\"свою\",\"сделать\",\"сеаой\",\"себе\",\"себя\",\"сегодня\",\"седьмой\",\"сейчас\",\"семнадцатый\",\"семнадцать\",\"семь\",\"сидеть\",\"сила\",\"сих\",\"сказал\",\"сказала\",\"сказать\",\"сколько\",\"слишком\",\"слово\",\"случай\",\"смотреть\",\"сначала\",\"снова\",\"со\",\"собой\",\"собою\",\"советский\",\"совсем\",\"спасибо\",\"спросить\",\"сразу\",\"стал\",\"старый\",\"стать\",\"стол\",\"сторона\",\"стоять\",\"страна\",\"суть\",\"считать\",\"т\",\"та\",\"так\",\"такая\",\"также\",\"таки\",\"такие\",\"такое\",\"такой\",\"там\",\"твои\",\"твой\",\"твоя\",\"твоё\",\"те\",\"тебе\",\"тебя\",\"тем\",\"теми\",\"теперь\",\"тех\",\"то\",\"тобой\",\"тобою\",\"товарищ\",\"тогда\",\"того\",\"тоже\",\"только\",\"том\",\"тому\",\"тот\",\"тою\",\"третий\",\"три\",\"тринадцатый\",\"тринадцать\",\"ту\",\"туда\",\"тут\",\"ты\",\"тысяч\",\"у\",\"увидеть\",\"уж\",\"уже\",\"улица\",\"уметь\",\"утро\",\"хороший\",\"хорошо\",\"хотел бы\",\"хотеть\",\"хоть\",\"хотя\",\"хочешь\",\"час\",\"часто\",\"часть\",\"чаще\",\"чего\",\"человек\",\"чем\",\"чему\",\"через\",\"четвертый\",\"четыре\",\"четырнадцатый\",\"четырнадцать\",\"что\",\"чтоб\",\"чтобы\",\"чуть\",\"шестнадцатый\",\"шестнадцать\",\"шестой\",\"шесть\",\"эта\",\"эти\",\"этим\",\"этими\",\"этих\",\"это\",\"этого\",\"этой\",\"этом\",\"этому\",\"этот\",\"эту\",\"я\",\"являюсь\"]\n",
    "    words = ' '.join([word for word in words.split() if word not in (stopwords)])\n",
    "    print(\">>> Убрано: \", a - len(words.split()))\n",
    "    return words\n",
    "    \n",
    "def usr_val(words):\n",
    "    \"\"\"\n",
    "    Функция позволяет добавить в train_update.csv новые данные для последущего улучшения модели. Если файла train_update.csv нет, он будет создан.\n",
    "    \n",
    "    PARAMS:\n",
    "    words(str) - Ваши слова\n",
    "    \n",
    "    RESULT:\n",
    "    Обновленный файл \n",
    "    \n",
    "    NO RETURN\n",
    "    \"\"\"\n",
    "    tmp = {}\n",
    "    try:\n",
    "        df = pd.read_csv(\"train_update.csv\")\n",
    "    except Exception: \n",
    "        df = pd.DataFrame(columns=[\"W\", \"T\"])\n",
    "    T = input(\">>> Введите компетенцию соответствующую вашим словам: \")\n",
    "    tmp[\"W\"] = words\n",
    "    tmp[\"T\"] = T\n",
    "    df = df.append(tmp, ignore_index=True)\n",
    "    df.to_csv(\"train_update.csv\")\n",
    "    print(\">>> Спасибо\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример вызова документации функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Функция получения текста из pdf файла\n",
      "    \n",
      "    PARAMS:\n",
      "    filename(str) - Имя pdf файла с расширением в той же директории или полный путь до файла(пример resume.pdf)\n",
      "    \n",
      "    RETURN:\n",
      "    words(str)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(pdf_text.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
